{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18a334b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b403f1",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cae4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indices(data, prop=1, val_prop=0.15, test_prop=0.15, rs=0):\n",
    "    \"\"\"Generated train, validation and test indices that will be used in the\n",
    "    dataloaders.\n",
    "\n",
    "    Args:\n",
    "        data (numpy.ndarray): 2-dimensional array of the dataset. The first column has\n",
    "            to contain the class (ex: cancer / no cancer) information.\n",
    "        prop (int, optional): Proportion of the dataset that is used to generate the\n",
    "            indices. Defaults to 1.\n",
    "        val_prop (float, optional): Proportion of data dedicated to the validation set.\n",
    "            Defaults to 0.15.\n",
    "        test_prop (float, optional): Proportion of data dedicated to the test set.\n",
    "            Defaults to 0.15.\n",
    "        rs (int, optional): Random state. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        (numpy.ndarray, numpy.ndarray, numpy.ndarray): Train, validation and test\n",
    "        indices.\n",
    "    \"\"\"\n",
    "    indices = list(range(len(data)))\n",
    "    \n",
    "    if test_prop != 0 :\n",
    "        train_idx, test_idx = train_test_split(\n",
    "            indices, test_size=test_prop, stratify=data[:,0], train_size=None, random_state=rs\n",
    "        )\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            train_idx,\n",
    "            test_size=val_prop / (1 - test_prop),\n",
    "            train_size=None,\n",
    "            stratify=data[train_idx,0],\n",
    "            random_state=rs,\n",
    "        )\n",
    "    else :\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            indices,\n",
    "            data[:,0],\n",
    "            test_size=val_prop,\n",
    "            train_size=None,\n",
    "            stratify=data[:,0],\n",
    "            random_state=rs,\n",
    "        )\n",
    "        test_idx=[]\n",
    "    if prop != 1:\n",
    "        modes = data[train_idx, 0]\n",
    "        subtrain_idx = []\n",
    "        for mode in np.unique(modes):\n",
    "            candidates = np.array(train_idx)[np.argwhere(modes == mode).flatten()]\n",
    "            selected_idx = candidates[: round(len(candidates) * prop)]\n",
    "            #selected_idx = np.random.choice(candidates, int(round(len(candidates)*prop)), replace=False)\n",
    "            subtrain_idx += selected_idx.tolist()\n",
    "        train_idx = subtrain_idx\n",
    "        print(len(train_idx))\n",
    "\n",
    "    return (train_idx, val_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e42c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_process_data_TCGA(\n",
    "    data_path,\n",
    "    label_path,\n",
    "    coding_genes=False,\n",
    "    coding_genes_file='../data/protein-coding_gene.txt'\n",
    "):\n",
    "    \"\"\"Reads and processes (including a normal standardardization) the TCGA data.\n",
    "\n",
    "    Args:\n",
    "        data_path (str) : path to dataset\n",
    "        label_path (str) : path to classes\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Numpy array of the processed data.\n",
    "    \"\"\"\n",
    "    \n",
    "    class_df = pd.read_parquet(label_path)\n",
    "    data_df = pd.read_parquet(data_path)\n",
    "    \n",
    "    if coding_genes:\n",
    "        protein_coding_file = pd.read_csv(coding_genes_file, '\\t')\n",
    "        ens_list = np.unique(protein_coding_file['ensembl_gene_id'].tolist()).tolist()\n",
    "        ens_list.pop()\n",
    "        selected_columns = ['caseID'] + ens_list\n",
    "        genes = data_df.columns\n",
    "        intersection = list(set(selected_columns) & set(genes))\n",
    "        data_df = data_df[intersection]\n",
    "\n",
    "    # merging the dataframes based on \"caseID\"\n",
    "    class_df[\"caseID\"] = class_df.apply(lambda row: row.cases.split(\"|\")[1], axis=1)\n",
    "    df = class_df.merge(data_df, on=\"caseID\", how=\"inner\")\n",
    "    #df = class_df.iloc[:100].merge(data_df.iloc[:100], on=\"caseID\", how=\"inner\")\n",
    "    \n",
    "    df = df.drop(columns=list(df.columns[:7]) + [df.columns[8]] + [df.columns[9]])  # columns management\n",
    "    \n",
    "    # encoding cancer names to integers\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[\"cancer_type\"] = le.fit_transform(df[\"cancer_type\"])\n",
    "    print(df.columns)\n",
    "    np_dataset = df.to_numpy(dtype=np.float32)\n",
    "\n",
    "    # normal standardardization\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    np_dataset[:, 1:] = scaler.fit_transform(np_dataset[:, 1:])\n",
    "\n",
    "    return np_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2b6ec",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd9a55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cancer_type', 'ENSG00000000003', 'ENSG00000000005', 'ENSG00000000419',\n",
      "       'ENSG00000000457', 'ENSG00000000460', 'ENSG00000000938',\n",
      "       'ENSG00000000971', 'ENSG00000001036', 'ENSG00000001084',\n",
      "       ...\n",
      "       'ENSG00000288658', 'ENSG00000288659', 'ENSG00000288660',\n",
      "       'ENSG00000288662', 'ENSG00000288663', 'ENSG00000288667',\n",
      "       'ENSG00000288669', 'ENSG00000288670', 'ENSG00000288674',\n",
      "       'ENSG00000288675'],\n",
      "      dtype='object', length=56903)\n"
     ]
    }
   ],
   "source": [
    "dataset = read_process_data_TCGA('mRNA.omics.parquet', 'label.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef270937",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = pd.read_parquet('mRNA.omics.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b1f0c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9349, 56903), (9349, 56903))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_orig.shape, dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33952247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7291, 1029, 1029)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = generate_indices(dataset, prop=1, val_prop=0.11, test_prop=0.11, rs=0)\n",
    "len(idx[0]), len(idx[1]), len(idx[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97a22fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_data = pd.DataFrame(data_orig.iloc[idx[0]], columns=data_orig.columns)\n",
    "nopretrain_data = pd.DataFrame(data_orig.iloc[idx[1]+idx[2]], columns=data_orig.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee66e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_data.to_parquet('pretrain_data.2.parquet')\n",
    "nopretrain_data.to_parquet('nopretrain_data.2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa941dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cancer_type', 'ENSG00000000003', 'ENSG00000000005', 'ENSG00000000419',\n",
      "       'ENSG00000000457', 'ENSG00000000460', 'ENSG00000000938',\n",
      "       'ENSG00000000971', 'ENSG00000001036', 'ENSG00000001084',\n",
      "       ...\n",
      "       'ENSG00000288658', 'ENSG00000288659', 'ENSG00000288660',\n",
      "       'ENSG00000288662', 'ENSG00000288663', 'ENSG00000288667',\n",
      "       'ENSG00000288669', 'ENSG00000288670', 'ENSG00000288674',\n",
      "       'ENSG00000288675'],\n",
      "      dtype='object', length=56903)\n"
     ]
    }
   ],
   "source": [
    "nopretrain_data_p = read_process_data_TCGA('nopretrain_data.2.parquet', 'label.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51273e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
